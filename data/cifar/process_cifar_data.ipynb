{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c174c60-d02b-4fd5-91e6-105425889e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802ec417-ca3d-4b9c-b01e-6d076a2d86a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcs for combining expert opinions\n",
    "def get_minority_opinion(x):\n",
    "    modes = stats.mode(x)[0]\n",
    "    for val in x:\n",
    "        if val not in modes:\n",
    "            return val\n",
    "    return np.random.choice(list(x))\n",
    "\n",
    "def add_minority(df, start, end):\n",
    "    col_name = 'minority{}-{}'.format(start, end)\n",
    "    include_vals = [i for i in range(start, end+1)]\n",
    "    df[col_name] = df.apply(\n",
    "        lambda x: get_minority_opinion(x[include_vals]), axis=1\n",
    "    )\n",
    "\n",
    "def add_consensus(df, start, end):\n",
    "    col_name = 'consensus{}-{}'.format(start, end)\n",
    "    include_vals = [i for i in range(start, end+1)]\n",
    "    df[col_name] = df.apply(lambda x: stats.mode(x[include_vals])[0][0], axis=1)\n",
    "    \n",
    "def create_experts(row, exp1_c, exp2_c, exp3_c):\n",
    "    if row['consensus'] in exp1_c:\n",
    "        row['expert1'] = row['consensus0-10']\n",
    "    else:\n",
    "        row['expert1'] = row['minority0-15']\n",
    "    if row['consensus'] in exp2_c:\n",
    "        row['expert2'] = row['consensus16-26']\n",
    "    else:\n",
    "        row['expert2'] = row['minority16-32'] \n",
    "    if row['consensus'] in exp3_c:\n",
    "        row['expert3'] = row['consensus33-43']\n",
    "    else:\n",
    "        row['expert3'] = row['minority33-48']\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b04d5f-bb49-4d69-969b-7766ed5373ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcs for merging classes into super-classes\n",
    "def combine_classes(row, class1, class2, class3):\n",
    "    for col in ['expert1', 'expert2', 'expert3','consensus']:\n",
    "        if row[col] in class1:\n",
    "            row[col] = 0\n",
    "        elif row[col] in class2:\n",
    "            row[col] = 1\n",
    "        else:\n",
    "            row[col] = 2\n",
    "    return row\n",
    "\n",
    "def combine_model_classes(row, c1, c2, c3):\n",
    "    m1 = row[0]\n",
    "    c1_prob = min(1.0, sum(m1[c1]))\n",
    "    c2_prob = min(1.0, sum(m1[c2]))\n",
    "    c3_prob = min(1.0, sum(m1[c3]))\n",
    "    return [[c1_prob, c2_prob, c3_prob]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf2293b-b1fd-4448-886e-aa05f2627881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/tpzk6y551s5bvtpwm5msn6740000gn/T/ipykernel_1017/2189925950.py:10: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  df['consensus'] = df.apply(lambda x: stats.mode(x)[0][0], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# create dataframe of expert and model predictions\n",
    "# new classes (e.g., class c1 is original classes 0, 1, and 2)\n",
    "c1 = [0,1,2]\n",
    "c2 = [3,4,5]\n",
    "c3 = [6,7,8,9]\n",
    "n_experts = 3\n",
    "\n",
    "expert_preds = pd.read_pickle(r'cifar_raw_annotations.pkl')\n",
    "df = pd.DataFrame(expert_preds)\n",
    "df['consensus'] = df.apply(lambda x: stats.mode(x)[0][0], axis=1)\n",
    "\n",
    "d = pd.read_pickle(r'cifar_raw_model_data.pkl')\n",
    "chosen_model = 55 # used 28, 46, 55\n",
    "n_models = 1\n",
    "chosen_model_preds = d['model_confs'][chosen_model]\n",
    "y_m = chosen_model_preds.reshape((10000,n_models,10))\n",
    "y_m_new = np.array([combine_model_classes(x, c1, c2, c3) for x in y_m])\n",
    "for i in range(3):\n",
    "    df['model_p'+str(i)] = y_m_new[:,0,i]\n",
    "df['model_pred_int'] = np.argmax([df['model_p'+str(i)] for i in range(3)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a285aa-56f2-4fd0-8709-cd155e2e4509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/tpzk6y551s5bvtpwm5msn6740000gn/T/ipykernel_1017/3449452709.py:19: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  df[col_name] = df.apply(lambda x: stats.mode(x[include_vals])[0][0], axis=1)\n",
      "/var/folders/2t/tpzk6y551s5bvtpwm5msn6740000gn/T/ipykernel_1017/3449452709.py:3: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  modes = stats.mode(x)[0]\n"
     ]
    }
   ],
   "source": [
    "# create experts\n",
    "\n",
    "# expert 1 (annotations 0-15)\n",
    "add_consensus(df, 0, 10)\n",
    "add_minority(df, 0, 15)\n",
    "# expert 2 (annotations 16-32)\n",
    "add_consensus(df, 16, 26)\n",
    "add_minority(df, 16, 32)\n",
    "# expert 3 (annotations 33-48)\n",
    "add_consensus(df, 33, 43)\n",
    "add_minority(df, 33, 48)\n",
    "\n",
    "df = df.apply(lambda x: create_experts(x, c1 + c3, c1 + c2, c2 + c3), axis=1)\n",
    "df = df.apply(lambda x: combine_classes(x, c1, c2, c3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64b2651b-58a9-4161-b058-8340f4174a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['expert1', 'expert2', 'expert3', 'consensus', 'model_p0', 'model_p1', 'model_p2', 'model_pred_int']].copy()\n",
    "for c in ['expert1', 'expert2', 'expert3', 'consensus']:\n",
    "    df[c] = df[c].astype(int)\n",
    "df.to_csv('cifar_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "655df90b-0ba8-49ab-ae26-ac355303dd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expert1</th>\n",
       "      <th>expert2</th>\n",
       "      <th>expert3</th>\n",
       "      <th>consensus</th>\n",
       "      <th>model_p0</th>\n",
       "      <th>model_p1</th>\n",
       "      <th>model_p2</th>\n",
       "      <th>model_pred_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.721072e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.001451e-09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9.041309e-05</td>\n",
       "      <td>1.120718e-08</td>\n",
       "      <td>9.999095e-01</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.709112e-01</td>\n",
       "      <td>9.374868e-07</td>\n",
       "      <td>8.290878e-01</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.470340e-01</td>\n",
       "      <td>5.637769e-01</td>\n",
       "      <td>8.918913e-02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9.286677e-08</td>\n",
       "      <td>2.337285e-07</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   expert1  expert2  expert3  consensus      model_p0      model_p1  \\\n",
       "0        0        1        1          1  8.721072e-09  1.000000e+00   \n",
       "1        2        2        2          2  9.041309e-05  1.120718e-08   \n",
       "2        2        2        2          2  1.709112e-01  9.374868e-07   \n",
       "3        0        0        2          0  3.470340e-01  5.637769e-01   \n",
       "4        2        0        2          2  9.286677e-08  2.337285e-07   \n",
       "\n",
       "       model_p2  model_pred_int  \n",
       "0  2.001451e-09             1.0  \n",
       "1  9.999095e-01             2.0  \n",
       "2  8.290878e-01             2.0  \n",
       "3  8.918913e-02             1.0  \n",
       "4  9.999996e-01             2.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e454f2-79df-428b-b291-565a211b5374",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set (n=750):\n",
      "\tclassifier (overall): 0.9226666666666666\n",
      "\t\t [0.821256038647343, 0.9620853080568721, 0.9608433734939759]\n",
      "\texpert 1: 0.9386666666666666\n",
      "\t\t [1.0, 0.7867298578199052, 0.9969879518072289]\n",
      "\texpert 2: 0.9093333333333333\n",
      "\t\t [1.0, 1.0, 0.7951807228915663]\n",
      "\texpert 3: 0.9\n",
      "\t\t [0.642512077294686, 1.0, 0.9969879518072289]\n"
     ]
    }
   ],
   "source": [
    "# get accuracies\n",
    "n = 750\n",
    "print('accuracy on test set (n={}):'.format(n))\n",
    "\n",
    "df['model_correct'] = df['model_pred_int']==df['consensus']\n",
    "test_accuracy = np.mean(df[:n]['model_correct'])\n",
    "class_wise_accs = list(df[:n].groupby('consensus').aggregate(\n",
    "        {'model_correct':'mean'}\n",
    ")['model_correct'])\n",
    "print(\"\\tclassifier (overall): {}\".format(test_accuracy))\n",
    "print(\"\\t\\t \" + str(class_wise_accs))\n",
    "\n",
    "for e in range(n_experts):\n",
    "    e_corr_col = 'expert{}_correct'.format(e+1)\n",
    "    df[e_corr_col] = df['expert'+str(e+1)]==df['consensus']\n",
    "    expert_acc = sum(df[:n]['expert'+str(e+1)]==df[:n]['consensus'])/n\n",
    "    class_wise_accs = list(df[:n].groupby('consensus').aggregate(\n",
    "            {e_corr_col:'mean'}\n",
    "    )[e_corr_col])\n",
    "    print (\"\\texpert {}: {}\".format(e+1, expert_acc))\n",
    "    print(\"\\t\\t \" + str(class_wise_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7895b4c0-854f-440e-9eea-19583bef432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data dict for our model\n",
    "y_h = np.array(df[['expert1','expert2','expert3']]) + 1\n",
    "y_m = [[df['model_p'+str(i)]] for i in range(3)]\n",
    "y_m = np.array(y_m).reshape((10000, 1, 3))\n",
    "\n",
    "out_dict = {\n",
    "    'Y_H' : y_h.tolist(),\n",
    "    'Y_M' : y_m.tolist(),\n",
    "    'n_models': n_models,\n",
    "    'n_humans': n_experts,\n",
    "    'K': 3\n",
    "}\n",
    "\n",
    "with open('data.pickle', 'wb') as handle:\n",
    "    pickle.dump(out_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2a65220-ebd6-4da4-a9b5-8f575688ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data dict for INFEXP model\n",
    "for start_point in [0, 250, 500]:\n",
    "    y_h = np.array(df[['expert'+str(i+1) for i in range(n_experts)]])\n",
    "    y_h = y_h.reshape((n_experts,len(df)))\n",
    "    d_new = np.array(df['consensus'])\n",
    "\n",
    "    y_m_new = np.array([df['model_p'+str(i)] for i in range(3)])\n",
    "    model_confs = np.array([y_m_new])\n",
    "    model_preds = np.array([[np.argmax(i) for i in j] for j in model_confs])\n",
    "\n",
    "    df['model_correct'] = df['model_pred_int']==df['consensus']\n",
    "    model_perf = np.array([[df['model_correct'].mean()]])\n",
    "    class_wise_perf = np.array(\n",
    "        df.groupby(\n",
    "            'consensus'\n",
    "        ).aggregate(\n",
    "            {'model_correct':'mean'}\n",
    "        )['model_correct']\n",
    "    )\n",
    "\n",
    "    n_models = 1\n",
    "    n_tests = 250\n",
    "    model_preds_dict_new = {\n",
    "        'model_confs' : model_confs[:,start_point:start_point+n_tests],\n",
    "        'model_preds' : model_preds[:,start_point:start_point+n_tests],\n",
    "        'true_targets' : d_new[start_point:start_point+n_tests],\n",
    "        'expert_preds' : y_h[:,start_point:start_point+n_tests],\n",
    "        'chosen_models' : np.array([0]),\n",
    "        'model_perf' : model_perf,\n",
    "        'model_perf_per_class' : class_wise_perf\n",
    "    }\n",
    "\n",
    "    with open('cifar_infexp{}.pickle'.format(start_point), 'wb') as handle:\n",
    "        pickle.dump(model_preds_dict_new, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82e2c53-6eef-407c-a0d1-a937ae21b86e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
