{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe107ecb-7b6d-4bda-b1ba-e348897ff9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f396dce4-5c53-4054-975b-d9be6935ed24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expert1</th>\n",
       "      <th>expert2</th>\n",
       "      <th>expert3</th>\n",
       "      <th>expert4</th>\n",
       "      <th>expert5</th>\n",
       "      <th>img_name</th>\n",
       "      <th>model_p0</th>\n",
       "      <th>model_p1</th>\n",
       "      <th>Y_H</th>\n",
       "      <th>consensus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00000211_006.png</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.999332</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00000211_022.png</td>\n",
       "      <td>0.013090</td>\n",
       "      <td>0.986910</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00000211_028.png</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.993304</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00000211_029.png</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.999482</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00000218_002.png</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.999544</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   expert1  expert2  expert3  expert4  expert5          img_name  model_p0  \\\n",
       "0        1        1        1        1        1  00000211_006.png  0.000668   \n",
       "1        1        1        1        1        1  00000211_022.png  0.013090   \n",
       "2        1        1        1        1        1  00000211_028.png  0.006696   \n",
       "3        1        1        1        1        1  00000211_029.png  0.000518   \n",
       "4        1        1        1        1        1  00000218_002.png  0.000456   \n",
       "\n",
       "   model_p1              Y_H  consensus  \n",
       "0  0.999332  [1, 1, 1, 1, 1]          1  \n",
       "1  0.986910  [1, 1, 1, 1, 1]          1  \n",
       "2  0.993304  [1, 1, 1, 1, 1]          1  \n",
       "3  0.999482  [1, 1, 1, 1, 1]          1  \n",
       "4  0.999544  [1, 1, 1, 1, 1]          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create combined dataframe of expert + model predictions\n",
    "human_label_path = 'nih_full_raw_data/all_findings_expert_labels/test_individual_readers.csv'\n",
    "n_experts = 5\n",
    "annotator_id_cols = [4343880271, 4343882583, 4343882785, 4343883593, 4343883996]\n",
    "human_labels = pd.read_csv(human_label_path)\n",
    "human_labels.reset_index(drop=True, inplace=True)\n",
    "annotations = human_labels.pivot(\n",
    "    index='Image ID', columns='Reader ID', values='Abnormal'\n",
    ").reset_index()\n",
    "\n",
    "m = pd.read_csv(\"cxr_model_predictions.csv\", index_col=0)\n",
    "m['img_name'] = m['img_name'].apply(lambda x: x[13:])\n",
    "m['score'] = m['score'].apply(lambda x: float(x[1:-1]))\n",
    "\n",
    "df = annotations.merge(m, left_on='Image ID', right_on='img_name')\n",
    "df = df.drop('Image ID', axis=1)\n",
    "df['Y_H'] = df.apply(lambda x: [x[c] for c in annotator_id_cols], axis=1)\n",
    "df['consensus'] = df['Y_H'].apply(lambda x: stats.mode(x, keepdims=True)[0][0])\n",
    "df['model_p0'] = 1-df['score']\n",
    "df.columns = [\n",
    "    'expert1', 'expert2', 'expert3', 'expert4', 'expert5', 'img_name',\n",
    "                'model_p1', 'Y_H', 'consensus','model_p0'\n",
    "]\n",
    "df = df[[\n",
    "    'expert1', 'expert2', 'expert3', 'expert4', 'expert5', 'img_name',\n",
    "                'model_p0', 'model_p1', 'Y_H', 'consensus'\n",
    "]]\n",
    "df.to_csv('data_clean.csv', index=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ec043d5-9cd6-4dc5-acf6-da1b4455a840",
   "metadata": {},
   "source": [
    "# save data dict for our model\n",
    "Y_H = np.array(list(df['Y_H'])) + 1\n",
    "Y_M = [[[1 - s, s]] for s in df['model_p1']]\n",
    "\n",
    "data_dict = {\n",
    "    'Y_M' : Y_M,\n",
    "    'Y_H' : Y_H.tolist(),\n",
    "    'n_models' : 1,\n",
    "    'n_humans' : n_experts,\n",
    "    'K' : 2\n",
    "}\n",
    "\n",
    "with open('data.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46a278ca-f3c4-4b9f-961f-30e68a461fdd",
   "metadata": {},
   "source": [
    "for shuffle_num in [1,2,3]:\n",
    "    df_shuffled = df.sample(frac=1, random_state=shuffle_num)\n",
    "\n",
    "    Y_H = np.array(list(df_shuffled['Y_H'])) + 1\n",
    "    Y_M = [[[1 - s, s]] for s in df_shuffled['model_p1']]\n",
    "\n",
    "    data_dict = {\n",
    "        'Y_M' : Y_M,\n",
    "        'Y_H' : Y_H.tolist(),\n",
    "        'n_models' : 1,\n",
    "        'n_humans' : n_experts,\n",
    "        'K' : 2\n",
    "    }\n",
    "\n",
    "    with open('data{}.pickle'.format(shuffle_num), 'wb') as handle:\n",
    "        pickle.dump(data_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2b82981-558d-4116-8399-637ec5d09f95",
   "metadata": {},
   "source": [
    "# save data dict for our model with noisy predictions\n",
    "Y_M_noisy = [[[1 - s, s]] for s in df['model_pred_noisy']]\n",
    "\n",
    "data_dict_noisy = {\n",
    "    'Y_M' : Y_M_noisy,\n",
    "    'Y_H' : Y_H.tolist(),\n",
    "    'n_models' : 1,\n",
    "    'n_humans' : n_experts,\n",
    "    'K' : 2\n",
    "}\n",
    "\n",
    "with open('data_noisy.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_dict_noisy, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa8230e4-af6e-4ed1-b87b-6006e10a36a5",
   "metadata": {},
   "source": [
    "# save data dict for our model with \"distribution shift\"\n",
    "Y_M_ds = np.concatenate([\n",
    "        Y_M[:125], \n",
    "        Y_M_noisy[125:250], \n",
    "        Y_M[250:375],\n",
    "        Y_M_noisy[375:500],\n",
    "        Y_M[500:625],\n",
    "        Y_M_noisy[625:750]\n",
    "])\n",
    "\n",
    "data_dict_ds = {\n",
    "    'Y_M' : Y_M_ds,\n",
    "    'Y_H' : Y_H.tolist()[:750],\n",
    "    'n_models' : 1,\n",
    "    'n_humans' : n_experts,\n",
    "    'K' : 2\n",
    "}\n",
    "\n",
    "with open('data_ds.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_dict_ds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1717b88-8cac-49ea-87af-e34cff76fad1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# get accuracies\n",
    "n = 250\n",
    "df['model_pred_int'] = df['model_p1'].apply(lambda x: 0 if x<0.5 else 1)\n",
    "df['noisy_pred_int'] = df['model_pred_noisy'].apply(lambda x: 0 if x<0.5 else 1)\n",
    "for start_point in [0, 250, 500]:\n",
    "    print('accuracy on test set ({}-{}):'.format(start_point, start_point+n))\n",
    "    sub = df[start_point:start_point+n]\n",
    "\n",
    "    test_accuracy = sum(sub['model_pred_int']==sub['consensus'])/n\n",
    "    print(\"\\tclassifier: {}\".format(test_accuracy))\n",
    "\n",
    "    test_accuracy_noisy = sum(sub['noisy_pred_int']==sub['consensus'])/n\n",
    "    print(\"\\tnoisy classifier: {}\".format(test_accuracy_noisy))\n",
    "\n",
    "    for e in range(n_experts):\n",
    "        expert_acc = sum(sub['expert'+str(e+1)]==sub['consensus'])/n\n",
    "        print (\"\\texpert {}: {}\".format(e+1, expert_acc))\n",
    "        \n",
    "total_n=len(df)\n",
    "print('accuracy overall:')\n",
    "sub = df[:total_n]\n",
    "\n",
    "test_accuracy = sum(sub['model_pred_int']==sub['consensus'])/total_n\n",
    "print(\"\\tclassifier: {}\".format(test_accuracy))\n",
    "\n",
    "test_accuracy_noisy = sum(sub['noisy_pred_int']==sub['consensus'])/total_n\n",
    "print(\"\\tnoisy classifier: {}\".format(test_accuracy_noisy))\n",
    "\n",
    "for e in range(n_experts):\n",
    "    expert_acc = sum(sub['expert'+str(e+1)]==sub['consensus'])/total_n\n",
    "    print (\"\\texpert {}: {}\".format(e+1, expert_acc))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80e5f17e-0511-4648-8f9a-6da83f1c6807",
   "metadata": {},
   "source": [
    "# create data dict for INFEXP model\n",
    "for shuffle_num in [\"\", 1,2,3]:\n",
    "    if shuffle_num==\"\":\n",
    "        df_shuffled = df\n",
    "    else:\n",
    "        df_shuffled = df.sample(frac=1, random_state=shuffle_num)\n",
    "\n",
    "    for start_point in [0,250,500]:\n",
    "        y_h = np.array(df_shuffled[['expert'+str(i+1) for i in range(n_experts)]])\n",
    "        y_h = y_h.transpose()\n",
    "        d_new = np.array(df_shuffled['consensus'])\n",
    "\n",
    "        y_m_new = np.array([[1 - s, s] for s in df_shuffled['model_p1']])\n",
    "        model_confs = np.array([y_m_new])\n",
    "        model_preds = np.array([[np.argmax(i) for i in j] for j in model_confs])\n",
    "\n",
    "        df_shuffled['model_correct'] = df_shuffled['model_pred_int']==df_shuffled['consensus']\n",
    "        model_perf = np.array([[df_shuffled['model_correct'].mean()]])\n",
    "        class_wise_perf = np.array(\n",
    "            df_shuffled.groupby(\n",
    "                'consensus'\n",
    "            ).aggregate(\n",
    "                {'model_correct':'mean'}\n",
    "            )['model_correct']\n",
    "        )\n",
    "\n",
    "        n_models = 1\n",
    "        model_preds_dict_new = {\n",
    "            'model_confs' : model_confs[:,start_point:start_point+250],\n",
    "            'model_preds' : model_preds[:,start_point:start_point+250],\n",
    "            'targets' : d_new[start_point:start_point+250],\n",
    "            'true_targets' : d_new[start_point:start_point+250],\n",
    "            'expert_preds' : y_h[:,start_point:start_point+250],\n",
    "            'chosen_models' : np.array([0]),\n",
    "            'model_perf' : model_perf,\n",
    "            'model_perf_per_class' : class_wise_perf\n",
    "        }\n",
    "\n",
    "        with open('nih_infexp{}s{}.pickle'.format(start_point, shuffle_num), 'wb') as handle:\n",
    "            pickle.dump(model_preds_dict_new, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e536bde-0c21-4c57-8e45-7a251cfa4523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
