{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270f8028-c8e4-49fc-8882-3c53b6f01f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7810f3f7-1199-4499-9129-f90c26089b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = ['clock', 'knife', 'oven', 'chair', 'bottle', 'keyboard']\n",
    "c2 = ['cat', 'elephant', 'dog', 'bird', 'bear']\n",
    "c3 = ['airplane', 'boat', 'car', 'truck', 'bicycle']\n",
    "\n",
    "def convert_to_tri_class(x, c1, c2, c3):\n",
    "    if x in c1:\n",
    "        c = 0\n",
    "    elif x in c2:\n",
    "        c = 1\n",
    "    else:\n",
    "        assert x in c3\n",
    "        c = 2\n",
    "    return c\n",
    "\n",
    "def convert_prob_to_tri_class(row, c1, c2, c3):\n",
    "    c1_sum = 0\n",
    "    for v in c1:\n",
    "        c1_sum += row[v]\n",
    "    c2_sum = 0\n",
    "    for v in c2:\n",
    "        c2_sum += row[v]\n",
    "    c3_sum = 0\n",
    "    for v in c3:\n",
    "        c3_sum += row[v]\n",
    "    row['model_0'] = min(1.0, c1_sum)\n",
    "    row['model_1'] = min(1.0, c2_sum)\n",
    "    row['model_2'] = min(1.0, c3_sum)\n",
    "    return row\n",
    "\n",
    "def combine_experts(rows):\n",
    "    true_result = rows.iloc[0]['image_category_new']\n",
    "    expert_predictions = rows['participant_classification_new']\n",
    "    \n",
    "    correct_responses = []\n",
    "    incorrect_responses = []\n",
    "    for pred in expert_predictions:\n",
    "        if pred==true_result:\n",
    "            correct_responses.append(pred)\n",
    "        else:\n",
    "            incorrect_responses.append(pred)\n",
    "            \n",
    "    expert_predictions = []\n",
    "    if len(correct_responses)>=2:\n",
    "        expert_predictions = correct_responses[:2]\n",
    "        if len(incorrect_responses)>=1:\n",
    "            expert_predctions.append(incorrect_responses[0])\n",
    "        else:\n",
    "            expert_predictions.append(correct_responses[2])\n",
    "    elif len(correct_responses)==1:\n",
    "        expert_predictions = [correct_responses[0]]\n",
    "        expert_predictions.extend(incorrect_responses[:2])\n",
    "    else:\n",
    "        expert_predictions = incorrect_responses[:3]\n",
    "    if true_result == 1:\n",
    "        expert_predictions = [expert_predictions[2], expert_predictions[0], expert_predictions[1]]\n",
    "    elif true_result == 2:\n",
    "        expert_predictions = [expert_predictions[1], expert_predictions[2], expert_predictions[0]]\n",
    "        \n",
    "    return expert_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b14c136-8747-4755-b0f1-dbe858575761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of expert and model predictions\n",
    "n_experts = 3\n",
    "df_model = pd.read_csv('model_preds_raw.csv')\n",
    "df_human = pd.read_csv(\"annotations_raw.csv\")\n",
    "noisy = True\n",
    "\n",
    "# take subset of noisier images\n",
    "df_human = df_human[df_human['noise_level']>95]\n",
    "df_model = df_model[df_model['noise_level']>95]\n",
    "\n",
    "df_human = df_human[[\n",
    " 'participant_id', 'image_id', 'image_name', 'noise_level', 'image_category',\n",
    " 'participant_classification', 'confidence', 'correct', 'total_accuracy'\n",
    "]]\n",
    "for c in ['participant_classification', 'image_category']:\n",
    "    df_human[c+\"_new\"] = df_human[c].apply(\n",
    "        convert_to_tri_class, args=(c1, c2, c3,)\n",
    "    )\n",
    "\n",
    "df_human_proc = pd.DataFrame(\n",
    "    df_human.groupby(['image_name', 'noise_level']).apply(combine_experts),\n",
    "    columns=[\"Y_H\"]\n",
    ")\n",
    "df_human_proc.reset_index(inplace=True)\n",
    "df_human_proc['consensus'] = df_human_proc['Y_H'].apply(\n",
    "    lambda x: stats.mode(x)[0][0]\n",
    ")\n",
    "for e in range(n_experts):\n",
    "    df_human_proc['expert'+str(e+1)] = df_human_proc['Y_H'].apply(lambda x: x[e])\n",
    "    \n",
    "df_model = df_model.apply(\n",
    "        convert_prob_to_tri_class, args=(c1, c2, c3,), axis=1\n",
    ")\n",
    "model_name = 'alexnet' if noisy else 'vgg19'\n",
    "dn_df = df_model[df_model['model_name']==model_name].copy()\n",
    "dn_df['model_pred_int'] = dn_df.apply(\n",
    "    lambda x: np.argmax([x['model_'+str(i)] for i in range(3)]), axis=1\n",
    ")\n",
    "dn_df = dn_df[['image_name', 'noise_level','model_0','model_1', 'model_2','model_pred_int']]\n",
    "\n",
    "df = dn_df.merge(df_human_proc, on=['image_name', 'noise_level'], how='right')\n",
    "df = df.sample(frac=1)\n",
    "df = df[df['consensus']!=-1].reset_index(drop=True)\n",
    "df.to_csv('imagenet_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79baebd6-e6f1-44ce-9f7c-a83ff4971b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>noise_level</th>\n",
       "      <th>model_0</th>\n",
       "      <th>model_1</th>\n",
       "      <th>model_2</th>\n",
       "      <th>model_pred_int</th>\n",
       "      <th>Y_H</th>\n",
       "      <th>consensus</th>\n",
       "      <th>expert1</th>\n",
       "      <th>expert2</th>\n",
       "      <th>expert3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n02123394_6265</td>\n",
       "      <td>110</td>\n",
       "      <td>0.043533</td>\n",
       "      <td>0.938086</td>\n",
       "      <td>0.018381</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n04548280_9121</td>\n",
       "      <td>125</td>\n",
       "      <td>0.553714</td>\n",
       "      <td>0.160425</td>\n",
       "      <td>0.285862</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 2]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n02111500_4875</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n04467665_1187</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.999513</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 0, 2]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n01592084_2422</td>\n",
       "      <td>125</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.996785</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name  noise_level   model_0   model_1   model_2  model_pred_int  \\\n",
       "0  n02123394_6265          110  0.043533  0.938086  0.018381               1   \n",
       "1  n04548280_9121          125  0.553714  0.160425  0.285862               0   \n",
       "2  n02111500_4875          110  0.000621  0.999017  0.000362               1   \n",
       "3  n04467665_1187          110  0.000382  0.000105  0.999513               2   \n",
       "4  n01592084_2422          125  0.002229  0.996785  0.000986               1   \n",
       "\n",
       "         Y_H  consensus  expert1  expert2  expert3  \n",
       "0  [1, 1, 1]          1        1        1        1  \n",
       "1  [0, 0, 2]          0        0        0        2  \n",
       "2  [1, 1, 1]          1        1        1        1  \n",
       "3  [2, 0, 2]          2        2        0        2  \n",
       "4  [1, 1, 1]          1        1        1        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4fc4803-4fe9-460a-9443-2144645eaf61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set (n=250):\n",
      "\tclassifier (overall): 0.9\n",
      "\t\t [0.872093023255814, 0.9764705882352941, 0.8481012658227848]\n",
      "\texpert 1: 0.844\n",
      "\t\t [0.9651162790697675, 0.5764705882352941, 1.0]\n",
      "\texpert 2: 0.912\n",
      "\t\t [0.9651162790697675, 1.0, 0.759493670886076]\n",
      "\texpert 3: 0.832\n",
      "\t\t [0.5232558139534884, 0.9882352941176471, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# get accuracies\n",
    "n = 250\n",
    "print('accuracy on test set (n={}):'.format(n))\n",
    "\n",
    "df['model_correct'] = df['model_pred_int']==df['consensus']\n",
    "test_accuracy = np.mean(df[:n]['model_correct'])\n",
    "class_wise_accs = list(df[:n].groupby('consensus').aggregate(\n",
    "        {'model_correct':'mean'}\n",
    ")['model_correct'])\n",
    "print(\"\\tclassifier (overall): {}\".format(test_accuracy))\n",
    "print(\"\\t\\t \" + str(class_wise_accs))\n",
    "\n",
    "for e in range(n_experts):\n",
    "    e_corr_col = 'expert{}_correct'.format(e+1)\n",
    "    df[e_corr_col] = df['expert'+str(e+1)]==df['consensus']\n",
    "    expert_acc = sum(df[:n]['expert'+str(e+1)]==df[:n]['consensus'])/n\n",
    "    class_wise_accs = list(df[:n].groupby('consensus').aggregate(\n",
    "            {e_corr_col:'mean'}\n",
    "    )[e_corr_col])\n",
    "    print (\"\\texpert {}: {}\".format(e+1, expert_acc))\n",
    "    print(\"\\t\\t \" + str(class_wise_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f94ab5-5572-4940-b87f-1a89119bce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data dict for our model\n",
    "y_h = np.array(df[['expert1','expert2','expert3']]) + 1\n",
    "y_m = [[df['model_'+str(i)]] for i in range(3)]\n",
    "y_m = np.array(y_m).reshape((len(df), 1, 3))\n",
    "\n",
    "out_dict = {\n",
    "    'Y_H' : y_h.tolist(),\n",
    "    'Y_M' : y_m.tolist(),\n",
    "    'n_models': 1,\n",
    "    'n_humans': n_experts,\n",
    "    'K': 3\n",
    "}\n",
    "\n",
    "ext = \"_noisy\" if noisy else \"\"\n",
    "with open('data' + ext + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(out_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ec82c3-1e3f-4ec4-933e-5f0c4815bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data dict for INFEXP model\n",
    "y_h = np.array(df[['expert'+str(i+1) for i in range(n_experts)]])\n",
    "y_h = y_h.reshape((n_experts,len(df)))\n",
    "d_new = np.array(df['consensus'])\n",
    "\n",
    "y_m_new = np.array([df['model_'+str(i)] for i in range(3)])\n",
    "model_confs = np.array([y_m_new])\n",
    "model_preds = np.array([[np.argmax(i) for i in j] for j in model_confs])\n",
    "\n",
    "df['model_correct'] = df['model_pred_int']==df['consensus']\n",
    "model_perf = np.array([[df['model_correct'].mean()]])\n",
    "class_wise_perf = np.array(\n",
    "    df.groupby(\n",
    "        'consensus'\n",
    "    ).aggregate(\n",
    "        {'model_correct':'mean'}\n",
    "    )['model_correct']\n",
    ")\n",
    "\n",
    "n_models = 1\n",
    "infexp_dict = {\n",
    "    'model_confs' : model_confs,\n",
    "    'model_preds' : model_preds,\n",
    "    'true_targets' : d_new,\n",
    "    'expert_preds' : y_h,\n",
    "    'chosen_models' : np.array([0]),\n",
    "    'model_perf' : model_perf,\n",
    "    'model_perf_per_class' : class_wise_perf\n",
    "}\n",
    "\n",
    "with open('imagenet_infexp.pickle', 'wb') as handle:\n",
    "    pickle.dump(infexp_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ae3e3-6714-4974-b330-e976fa55d146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
