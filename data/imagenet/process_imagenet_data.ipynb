{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270f8028-c8e4-49fc-8882-3c53b6f01f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import calibration as cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7810f3f7-1199-4499-9129-f90c26089b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = ['clock', 'knife', 'oven', 'chair', 'bottle', 'keyboard']\n",
    "c2 = ['cat', 'elephant', 'dog', 'bird', 'bear']\n",
    "c3 = ['airplane', 'boat', 'car', 'truck', 'bicycle']\n",
    "\n",
    "def convert_to_tri_class(x, c1, c2, c3):\n",
    "    if x in c1:\n",
    "        c = 0\n",
    "    elif x in c2:\n",
    "        c = 1\n",
    "    else:\n",
    "        assert x in c3\n",
    "        c = 2\n",
    "    return c\n",
    "\n",
    "def convert_prob_to_tri_class(row, c1, c2, c3):\n",
    "    c1_sum = 0\n",
    "    for v in c1:\n",
    "        c1_sum += row[v]\n",
    "    c2_sum = 0\n",
    "    for v in c2:\n",
    "        c2_sum += row[v]\n",
    "    c3_sum = 0\n",
    "    for v in c3:\n",
    "        c3_sum += row[v]\n",
    "    row['model_p0'] = min(1.0, c1_sum)\n",
    "    row['model_p1'] = min(1.0, c2_sum)\n",
    "    row['model_p2'] = min(1.0, c3_sum)\n",
    "    return row\n",
    "\n",
    "def combine_experts(rows):\n",
    "    true_result = rows.iloc[0]['image_category_new']\n",
    "    expert_predictions = rows['participant_classification_new']\n",
    "    \n",
    "    correct_responses = []\n",
    "    incorrect_responses = []\n",
    "    for pred in expert_predictions:\n",
    "        if pred==true_result:\n",
    "            correct_responses.append(pred)\n",
    "        else:\n",
    "            incorrect_responses.append(pred)\n",
    "            \n",
    "    expert_predictions = []\n",
    "    if len(correct_responses)>=2:\n",
    "        expert_predictions = correct_responses[:2]\n",
    "        if len(incorrect_responses)>=1:\n",
    "            expert_predictions.append(incorrect_responses[0])\n",
    "        else:\n",
    "            expert_predictions.append(correct_responses[2])\n",
    "    elif len(correct_responses)==1:\n",
    "        expert_predictions = [correct_responses[0]]\n",
    "        expert_predictions.extend(incorrect_responses[:2])\n",
    "    else:\n",
    "        expert_predictions = incorrect_responses[:3]\n",
    "    if true_result == 1:\n",
    "        expert_predictions = [expert_predictions[2], expert_predictions[0], expert_predictions[1]]\n",
    "    elif true_result == 2:\n",
    "        expert_predictions = [expert_predictions[1], expert_predictions[2], expert_predictions[0]]\n",
    "        \n",
    "    return expert_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b14c136-8747-4755-b0f1-dbe858575761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/tpzk6y551s5bvtpwm5msn6740000gn/T/ipykernel_1016/2789766101.py:28: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  lambda x: stats.mode(x)[0][0] if stats.mode(x)[1][0] > 1 else -1\n"
     ]
    }
   ],
   "source": [
    "# create dataframe of expert and model predictions\n",
    "n_experts = 3\n",
    "noisy = False\n",
    "distribution_shift = False\n",
    "df_model = pd.read_csv('model_preds_raw.csv')\n",
    "df_human = pd.read_csv(\"annotations_raw.csv\")\n",
    "\n",
    "if not distribution_shift:\n",
    "    # take subset of noisier images\n",
    "    df_human = df_human[df_human['noise_level']>95]\n",
    "    df_model = df_model[df_model['noise_level']>95]\n",
    "\n",
    "df_human = df_human[[\n",
    " 'participant_id', 'image_id', 'image_name', 'noise_level', 'image_category',\n",
    " 'participant_classification', 'confidence', 'correct', 'total_accuracy'\n",
    "]]\n",
    "for c in ['participant_classification', 'image_category']:\n",
    "    df_human[c+\"_new\"] = df_human[c].apply(\n",
    "        convert_to_tri_class, args=(c1, c2, c3,)\n",
    "    )\n",
    "\n",
    "df_human_proc = pd.DataFrame(\n",
    "    df_human.groupby(['image_name', 'noise_level']).apply(combine_experts),\n",
    "    columns=[\"Y_H\"]\n",
    ")\n",
    "df_human_proc.reset_index(inplace=True)\n",
    "df_human_proc['consensus'] = df_human_proc['Y_H'].apply(\n",
    "    lambda x: stats.mode(x)[0][0] if stats.mode(x)[1][0] > 1 else -1\n",
    ")\n",
    "for e in range(n_experts):\n",
    "    df_human_proc['expert'+str(e+1)] = df_human_proc['Y_H'].apply(lambda x: x[e])\n",
    "    \n",
    "df_model = df_model.apply(\n",
    "        convert_prob_to_tri_class, args=(c1, c2, c3,), axis=1\n",
    ")\n",
    "model_name = 'alexnet' if noisy else 'vgg19'\n",
    "dn_df = df_model[df_model['model_name']==model_name].copy()\n",
    "dn_df['model_pred_int'] = dn_df.apply(\n",
    "    lambda x: np.argmax([x['model_p'+str(i)] for i in range(3)]), axis=1\n",
    ")\n",
    "dn_df = dn_df[['image_name', 'noise_level','model_p0','model_p1', 'model_p2','model_pred_int']]\n",
    "\n",
    "df = df_human_proc.merge(dn_df, on=['image_name', 'noise_level'], how='inner')\n",
    "df = df[df['consensus']!=-1].reset_index(drop=True)\n",
    "\n",
    "# shuffle rows\n",
    "np.random.seed(1)\n",
    "order = np.array([i for i in range(len(df))])\n",
    "np.random.shuffle(order)\n",
    "df = df.loc[order]\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "if distribution_shift:\n",
    "    df_before_ds = df[df['noise_level']==80][:375]\n",
    "    df_after_ds = df[df['noise_level']==125][:375]\n",
    "    df = pd.concat([\n",
    "        df_before_ds[:125], \n",
    "        df_after_ds[:125], \n",
    "        df_before_ds[125:250], \n",
    "        df_after_ds[125:250],\n",
    "        df_before_ds[250:],\n",
    "        df_after_ds[250:]\n",
    "    ])\n",
    "    \n",
    "if noisy==False and distribution_shift==False:\n",
    "    df.to_csv('imagenet_processed.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa0fe7bc-ff85-4368-99d2-c4bb4e28a8e8",
   "metadata": {},
   "source": [
    "dn_df_a = df_model[df_model['model_name']=='alexnet'].copy()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5a1c4ad-c5f1-43f6-b132-55a302bbdc7e",
   "metadata": {},
   "source": [
    "dn_df_a['model_pred_int'] = dn_df_a.apply(\n",
    "    lambda x: np.argmax([x['model_'+str(i)] for i in range(3)]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e6a045a-be0a-43a2-ae03-fa77d212bfa9",
   "metadata": {},
   "source": [
    "dn_df_a = dn_df_a[['image_name', 'noise_level','model_0','model_1', 'model_2','model_pred_int']]\n",
    "\n",
    "df_a = df_human_proc.merge(dn_df_a, on=['image_name', 'noise_level'], how='inner')\n",
    "df_a = df_a[df_a['consensus']!=-1].reset_index(drop=True)\n",
    "\n",
    "# shuffle rows\n",
    "np.random.seed(1)\n",
    "order = np.array([i for i in range(len(df_a))])\n",
    "np.random.shuffle(order)\n",
    "df_a = df_a.loc[order]\n",
    "df_a.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bad3704e-a458-4d28-a2e6-576ec4bd1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c7e15f9-5148-44b8-84e3-494c1812940f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclassifier (overall): 0.9306666666666666\n",
      "\t\t [0.9124087591240876, 0.95, 0.9322033898305084]\n"
     ]
    }
   ],
   "source": [
    "df['model_correct'] = df['model_pred_int']==df['consensus']\n",
    "test_accuracy = np.mean(df[:n]['model_correct'])\n",
    "class_wise_accs = list(df[:n].groupby('consensus').aggregate(\n",
    "        {'model_correct':'mean'}\n",
    ")['model_correct'])\n",
    "print(\"\\tclassifier (overall): {}\".format(test_accuracy))\n",
    "print(\"\\t\\t \" + str(class_wise_accs))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45cf0bbc-612a-4ae4-8456-10231b22688e",
   "metadata": {},
   "source": [
    "df_a['model_correct'] = df_a['model_pred_int']==df_a['consensus']\n",
    "test_accuracy = np.mean(df_a[:n]['model_correct'])\n",
    "class_wise_accs = list(df_a[:n].groupby('consensus').aggregate(\n",
    "        {'model_correct':'mean'}\n",
    ")['model_correct'])\n",
    "print(\"\\tclassifier (overall): {}\".format(test_accuracy))\n",
    "print(\"\\t\\t \" + str(class_wise_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4fc4803-4fe9-460a-9443-2144645eaf61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set (n=250):\n",
      "\tclassifier (overall): 0.916\n",
      "\t\t [0.9157894736842105, 0.922077922077922, 0.9102564102564102]\n",
      "\t\tECE = 0.008347642802963608; cal error = 0.045566160989114375\n",
      "\texpert 1: 0.82\n",
      "\t\t [1.0, 0.44155844155844154, 0.9743589743589743]\n",
      "\texpert 2: 0.888\n",
      "\t\t [1.0, 1.0, 0.6410256410256411]\n",
      "\texpert 3: 0.828\n",
      "\t\t [0.5684210526315789, 0.974025974025974, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# get accuracies\n",
    "n = 250\n",
    "print('accuracy on test set (n={}):'.format(n))\n",
    "\n",
    "df['model_correct'] = df['model_pred_int']==df['consensus']\n",
    "test_accuracy = np.mean(df[:n]['model_correct'])\n",
    "class_wise_accs = list(df[:n].groupby('consensus').aggregate(\n",
    "        {'model_correct':'mean'}\n",
    ")['model_correct'])\n",
    "print(\"\\tclassifier (overall): {}\".format(test_accuracy))\n",
    "print(\"\\t\\t \" + str(class_wise_accs))\n",
    "probs = np.array(df[['model_p0','model_p1','model_p2']])\n",
    "ece = cal.get_ece(probs, df['consensus'])\n",
    "cal_error = cal.get_calibration_error(probs, df['consensus'])\n",
    "print(\"\\t\\tECE = {}; cal error = {}\".format(ece, cal_error))\n",
    "\n",
    "for e in range(n_experts):\n",
    "    e_corr_col = 'expert{}_correct'.format(e+1)\n",
    "    df[e_corr_col] = df['expert'+str(e+1)]==df['consensus']\n",
    "    expert_acc = sum(df[:n]['expert'+str(e+1)]==df[:n]['consensus'])/n\n",
    "    class_wise_accs = list(df[:n].groupby('consensus').aggregate(\n",
    "            {e_corr_col:'mean'}\n",
    "    )[e_corr_col])\n",
    "    print (\"\\texpert {}: {}\".format(e+1, expert_acc))\n",
    "    print(\"\\t\\t \" + str(class_wise_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19f94ab5-5572-4940-b87f-1a89119bce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data dict for our model\n",
    "y_h = np.array(df[['expert1','expert2','expert3']]) + 1\n",
    "y_m = [[df['model_p'+str(i)]] for i in range(3)]\n",
    "y_m = np.array(y_m).reshape((len(df), 1, 3))\n",
    "\n",
    "out_dict = {\n",
    "    'Y_H' : y_h.tolist(),\n",
    "    'Y_M' : y_m.tolist(),\n",
    "    'n_models': 1,\n",
    "    'n_humans': n_experts,\n",
    "    'K': 3\n",
    "}\n",
    "\n",
    "ext = \"\"\n",
    "if noisy:\n",
    "    ext += \"_noisy\"\n",
    "if distribution_shift:\n",
    "    ext += \"_ds\" \n",
    "    \n",
    "with open('data' + ext + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(out_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28b27b98-daf9-436c-b13d-918cb50a4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data dict for INFEXP model\n",
    "for start_point in [0, 250, 500]:\n",
    "    y_h = np.array(df[['expert'+str(i+1) for i in range(n_experts)]])\n",
    "    y_h = y_h.reshape((n_experts,len(df)))\n",
    "    d_new = np.array(df['consensus'])\n",
    "\n",
    "    y_m_new = np.array([df['model_p'+str(i)] for i in range(3)])\n",
    "    model_confs = np.array([y_m_new])\n",
    "    model_preds = np.array([[np.argmax(i) for i in j] for j in model_confs])\n",
    "\n",
    "    df['model_correct'] = df['model_pred_int']==df['consensus']\n",
    "    model_perf = np.array([[df['model_correct'].mean()]])\n",
    "    class_wise_perf = np.array(\n",
    "        df.groupby(\n",
    "            'consensus'\n",
    "        ).aggregate(\n",
    "            {'model_correct':'mean'}\n",
    "        )['model_correct']\n",
    "    )\n",
    "\n",
    "    n_models = 1\n",
    "    n_tests = 250\n",
    "    infexp_dict = {\n",
    "        'model_confs' : model_confs[:,start_point:start_point+n_tests],\n",
    "        'model_preds' : model_preds[:,start_point:start_point+n_tests],\n",
    "        'true_targets' : d_new[start_point:start_point+n_tests],\n",
    "        'expert_preds' : y_h[:,start_point:start_point+n_tests],\n",
    "        'chosen_models' : np.array([0]),\n",
    "        'model_perf' : model_perf,\n",
    "        'model_perf_per_class' : class_wise_perf\n",
    "    }\n",
    "\n",
    "    with open('imagenet_infexp{}.pickle'.format(start_point), 'wb') as handle:\n",
    "        pickle.dump(infexp_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ae3e3-6714-4974-b330-e976fa55d146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
